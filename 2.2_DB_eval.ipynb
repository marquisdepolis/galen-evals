{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create combined schema of tables\n",
    "import os\n",
    "import glob\n",
    "import sqlite3\n",
    "import json\n",
    "import config\n",
    "import importlib\n",
    "importlib.reload(config)\n",
    "from config import config, reset_config\n",
    "from sqlalchemy import create_engine, MetaData, Table, Column, String\n",
    "import re\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "def combine_schemas(db_files):\n",
    "    combined_schema = {}\n",
    "\n",
    "    for db_file in db_files:\n",
    "        engine = create_engine('sqlite:///' + db_file)\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Get all tables\n",
    "        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "        tables = cursor.fetchall()\n",
    "\n",
    "        for table in tables:\n",
    "            table_name = table[0]\n",
    "            metadata_obj = MetaData()\n",
    "            \n",
    "            # Get table schema\n",
    "            cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "            schema = cursor.fetchall()\n",
    "\n",
    "            # Create a Table object to store schema info\n",
    "            table_obj = Table(table_name, metadata_obj)\n",
    "\n",
    "            for column in schema:\n",
    "                col_name, col_type = column[1], column[2]\n",
    "                # Add column to the table object\n",
    "                table_obj.append_column(Column(col_name, String))\n",
    "\n",
    "            # Serialize table schema\n",
    "            schema_info = [{\"column_name\": col.name, \"data_type\": str(col.type)} for col in table_obj.columns]\n",
    "            combined_schema[f\"{table_name} in {db_file}\"] = schema_info\n",
    "\n",
    "        conn.close()\n",
    "\n",
    "    return combined_schema\n",
    "\n",
    "def save_schema_to_json(combined_schema, filename=config.db_schema):\n",
    "    with open(filename, \"w\") as file:\n",
    "        json.dump(combined_schema, file, indent=4)\n",
    "\n",
    "# SQL check\n",
    "def extract_sql(llm_response: str) -> str:\n",
    "    # If the llm_response contains a markdown code block, with or without the sql tag, extract the sql from it\n",
    "    sql = re.search(r\"```sql\\n(.*)```\", llm_response, re.DOTALL)\n",
    "    if sql:\n",
    "        log.info(f\"Output from LLM: {llm_response} \\nExtracted SQL: {sql.group(1)}\")\n",
    "        return sql.group(1)\n",
    "\n",
    "    sql = re.search(r\"```(.*)```\", llm_response, re.DOTALL)\n",
    "    if sql:\n",
    "        log.info(f\"Output from LLM: {llm_response} \\nExtracted SQL: {sql.group(1)}\")\n",
    "        return sql.group(1)\n",
    "\n",
    "    return llm_response\n",
    "\n",
    "def is_sql_valid(sql: str) -> bool:\n",
    "    # This is a check to see the SQL is valid and should be run\n",
    "    # This simple function just checks if the SQL contains a SELECT statement\n",
    "\n",
    "    if \"SELECT\" in sql.upper():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Define your directory path\n",
    "db_directory = \"/Users/rohit/Library/CloudStorage/OneDrive-Personal/SM_RK shared folder/Coding_Analysis/Galen/Galen_dbrun/db\"\n",
    "db_files = glob.glob(os.path.join(db_directory, \"*.db\"))\n",
    "all_schemas = combine_schemas(db_files)\n",
    "save_schema_to_json(all_schemas)\n",
    "# Now the schema is saved in 'combined_schema.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM checks to write a SQL query\n",
    "import replicate\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import config\n",
    "import time\n",
    "import importlib\n",
    "importlib.reload(config)\n",
    "from config import config, reset_config\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from config import config\n",
    "config.set_mode(\"dbs\")\n",
    "\n",
    "folder_path = 'files'\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "INSTRUCTION = config.INSTRUCTION\n",
    "F_NAME = config.F_NAME\n",
    "\n",
    "def load_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "db_desc = load_file(config.db_layout)\n",
    "all_schemas = load_file(config.db_schema)\n",
    "\n",
    "df = pd.read_excel(config.questions)\n",
    "df.to_excel(config.q_original, index=False)\n",
    "\n",
    "df['Question'] = df['Question'].str.strip()  # Removes leading/trailing whitespace\n",
    "\n",
    "# Check for duplicate questions\n",
    "duplicates = df.duplicated(subset=['Question'], keep=False)\n",
    "if duplicates.any():\n",
    "    print(\"Duplicates found. Removing duplicates.\")\n",
    "    df = df.drop_duplicates(subset=['Question'], keep='first')\n",
    "    df.to_excel(config.q_db, index=False)\n",
    "else:\n",
    "    print(\"No duplicates found.\")\n",
    "\n",
    "# DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Question', 'Response', 'Latency', 'Category', 'Type'])\n",
    "\n",
    "models = {\n",
    "    # \"qwen-14b\": \"nomagick/qwen-14b-chat:f9e1ed25e2073f72ff9a3f46545d909b1078e674da543e791dec79218072ae70\",\n",
    "    \"falcon-40b\": \"joehoover/falcon-40b-instruct:7d58d6bddc53c23fa451c403b2b5373b1e0fa094e4e0d1b98c3d02931aa07173\",\n",
    "    \"yi-34b\": \"01-ai/yi-34b-chat:914692bbe8a8e2b91a4e44203e70d170c9c5ccc1359b283c84b0ec8d47819a46\",\n",
    "    \"mistral-7b\": \"mistralai/mistral-7b-instruct-v0.2:f5701ad84de5715051cb99d550539719f8a7fbcf65e0e62a3d1eb3f94720764e\",\n",
    "    # \"llama2-70b\": \"meta/llama-2-70b-chat\",\n",
    "    \"noushermes2\": \"nateraw/nous-hermes-2-solar-10.7b:1e918ab6ffd5872c21fba21a511f344fd12ac0edff6302c9cd260395c7707ff4\",\n",
    "    \"mixtral-instruct\": \"mistralai/mixtral-8x7b-instruct-v0.1:2b56576fcfbe32fa0526897d8385dd3fb3d36ba6fd0dbe033c72886b81ade93e\",\n",
    "    # \"deepseek_33bq\": \"kcaverly/deepseek-coder-33b-instruct-gguf:ea964345066a8868e43aca432f314822660b72e29cab6b4b904b779014fe58fd\",\n",
    "    }\n",
    "\n",
    "prompt_for_qwen=\"\"\"<|im_start|>system\\n {INSTRUCTION}. Please write the appropriate SQL query using these three tables. The schemas are as {all_schemas}. Try to answer the following question. The SQL should be returned within ''' SQL query '''. <|im_end|>\\n<|im_start|>user\\n{question}<|im_end|>\\n<|im_start|>assistant\\n\"\"\"\n",
    "prompt_for_hermes = \"\"\"[\n",
    "{{\n",
    "  \"role\": \"system\",\n",
    "  \"content\": \"{INSTRUCTION}. Please write the appropriate SQL query using these three tables. The schemas are as {all_schemas}. Try to answer the following question. The SQL should be returned within ''' SQL query ''' \" \n",
    "}},\n",
    "{{\n",
    "  \"role\": \"user\",\n",
    "  \"content\": {question}\n",
    "}}\n",
    "]\"\"\"\n",
    "\n",
    "# Iterate through each model\n",
    "for model_key, model_value in models.items():\n",
    "    responses = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        qn = row['Question']\n",
    "        question = json.dumps(qn)\n",
    "\n",
    "        if model_key in [\"yi-34b\", \"qwen-14b\"]:\n",
    "            prompt = prompt_for_qwen.format(INSTRUCTION=INSTRUCTION, all_schemas=all_schemas, question=question)\n",
    "        elif model_key == \"noushermes2\":  # Hermes model\n",
    "            prompt = prompt_for_hermes.format(INSTRUCTION=INSTRUCTION, all_schemas=all_schemas,question=question)\n",
    "        else:\n",
    "            prompt = f\"{INSTRUCTION}. Please write the appropriate SQL query using these three different dbs, and their schemas are as {all_schemas}. Try to answer the following question. Only the SQL should be returned within ''' SQL query '''. {question}\"\n",
    "\n",
    "        start_time = time.time()  # Record the start time\n",
    "\n",
    "        try:\n",
    "            print(prompt)\n",
    "            output = replicate.run(\n",
    "                model_value,\n",
    "                input={\n",
    "                  \"debug\": False,\n",
    "                #   \"top_k\": 50,\n",
    "                  \"top_p\": 0.9,\n",
    "                  \"prompt\": prompt,\n",
    "                  \"temperature\": 0.7,\n",
    "                  \"max_new_tokens\": 500,\n",
    "                  \"min_new_tokens\": -1\n",
    "                }\n",
    "            )\n",
    "            response = \"\"\n",
    "            response_parts = []  # Initialize an empty list to collect string representations\n",
    "            for item in output:\n",
    "                item_str = str(item).strip()  # Convert item to string\n",
    "                response += item_str # if len(item_str) == 1 else f\" {item_str}\"\n",
    "\n",
    "            response = response.strip()\n",
    "            extracted_sql = extract_sql(response) # Get only the SQL query\n",
    "            valid = is_sql_valid(response) # Check if the SQL query is valid\n",
    "            response = {\n",
    "                \"response\": extracted_sql,\n",
    "                \"is_valid\": valid\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            response = f\"Error: {e}\"\n",
    "        print(f\"Response is: {extracted_sql}\")\n",
    "        end_time = time.time()  # Record the end time\n",
    "        latency = end_time - start_time  # Calculate latency\n",
    "\n",
    "        new_row = pd.DataFrame({'Model': [model_key], 'Question': [qn], 'Response': [extracted_sql], 'Latency': [latency], 'Valid': [valid] 'Category': [row['Category']] , 'Type': [row['Type']] })\n",
    "        results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "        if index % 2 == 0:  # Save every 10 questions, adjust as needed\n",
    "            results_df.to_excel(config.llmresults_file_path, index=False, sheet_name='Sheet1')\n",
    "\n",
    "results_df.to_excel(config.llmresults_file_path, index=False, sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-4 writes a SQL query\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import openai\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "from config import config\n",
    "config.set_mode(\"dbs\")\n",
    "\n",
    "def load_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "db_desc = load_file(config.db_layout)\n",
    "all_schemas = load_file(config.db_schema)\n",
    "\n",
    "folder_path = 'files'\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "INSTRUCTION = config.INSTRUCTION\n",
    "F_NAME = config.F_NAME\n",
    "GPT_MODEL = config.GPT_MODEL\n",
    "INPUT_CSV_PATH = config.questions\n",
    "OUTPUT_CSV_PATH = config.gpt4results_csv_path\n",
    "\n",
    "client = OpenAI()\n",
    "def show_json(obj):\n",
    "    print(json.loads(obj.model_dump_json()))\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=f\"{F_NAME} AI Evaluator via reading DB\",\n",
    "    instructions=INSTRUCTION,\n",
    "    model=GPT_MODEL,\n",
    ")\n",
    "show_json(assistant)\n",
    "\n",
    "# Utility functions\n",
    "def read_csv(file_path):\n",
    "    return pd.read_excel(file_path)\n",
    "\n",
    "def process_data_for_gpt(data):\n",
    "    prompts = []\n",
    "    for _, row in data.iterrows():\n",
    "        question = row['Question']\n",
    "        prompt = f\"Please write the appropriate SQL query using these table schemas {all_schemas} to answer the following question. The SQL should be returned within ''' SQL query '''.:\\n\\n{question}\"\n",
    "        prompts.append(prompt)\n",
    "    return prompts\n",
    "\n",
    "def submit_message_and_create_run(assistant_id, prompt):\n",
    "    thread = client.beta.threads.create() # If you replace this globally it appends all answers to the one before.\n",
    "    client.beta.threads.messages.create(thread_id=thread.id, role=\"user\", content=prompt)\n",
    "    return client.beta.threads.runs.create(thread_id=thread.id, assistant_id=assistant_id), thread\n",
    "\n",
    "def wait_on_run_and_get_response(run, thread):\n",
    "    while run.status == \"queued\" or run.status == \"in_progress\":\n",
    "        run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "        time.sleep(0.5)\n",
    "    messages = client.beta.threads.messages.list(thread_id=thread.id, order=\"asc\")\n",
    "    return [m.content[0].text.value for m in messages if m.role == 'assistant']\n",
    "\n",
    "def create_output_csv(data, responses, validity, latencies, model_name, interim_csv_path):\n",
    "    new_rows = []\n",
    "    for question, response, latency, validity, category, type in zip(data['Question'], responses, latencies, validity, data['Category'], data['Type']):\n",
    "        new_rows.append({'Model': model_name, 'Question': question, 'Response': response, 'Latency': latency, 'Valid': validity, 'Category': category, 'Type': type})\n",
    "    new_data = pd.DataFrame(new_rows)\n",
    "    new_data.to_excel(interim_csv_path, index=False)\n",
    "\n",
    "data = read_csv(INPUT_CSV_PATH)\n",
    "prompts = process_data_for_gpt(data)\n",
    "ASSISTANT_ID = assistant.id\n",
    "\n",
    "responses = []\n",
    "latencies = []\n",
    "valid = []\n",
    "for prompt in prompts:\n",
    "    start_time = time.time()  # Capture start time\n",
    "    run, thread = submit_message_and_create_run(ASSISTANT_ID, prompt)\n",
    "    response = wait_on_run_and_get_response(run, thread)\n",
    "    if isinstance(response, list):\n",
    "        response = ' '.join(map(str, response))\n",
    "    response = response.replace(\"\\\\\\\\n\", \"\\\\n\")\n",
    "    response = response.strip()\n",
    "    extracted_sql = extract_sql(response) # Get only the SQL query\n",
    "    validity = is_sql_valid(response) # Check if the SQL query is valid\n",
    "    response = {\n",
    "        \"response\": extracted_sql,\n",
    "        \"is_valid\": valid\n",
    "    }\n",
    "    print(response)\n",
    "    responses.append(extracted_sql)\n",
    "    valid.append(validity)\n",
    "    end_time = time.time()  # Capture end time\n",
    "    latency = end_time - start_time  # Calculate latency\n",
    "    latencies.append(latency)  # Store latency\n",
    "\n",
    "create_output_csv(data, responses, valid, latencies, GPT_MODEL, OUTPUT_CSV_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
